{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0  58.0    4        1          2        0   2143.0        1     0        2   \n",
       "1  44.0    9        2          1        0     29.0        1     0        2   \n",
       "2  33.0    2        1          1        0      2.0        1     1        2   \n",
       "3  47.0    1        1          3        0   1506.0        1     0        2   \n",
       "4  33.0   11        2          3        0      1.0        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  target  \n",
       "0  5.0      8     261.0       1.0     -1         0         3       0  \n",
       "1  5.0      8     151.0       1.0     -1         0         3       0  \n",
       "2  5.0      8      76.0       1.0     -1         0         3       0  \n",
       "3  5.0      8      92.0       1.0     -1         0         3       0  \n",
       "4  5.0      8     198.0       1.0     -1         0         3       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, auc, f1_score, accuracy_score, precision_score, recall_score, roc_curve \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as Sampling_Pipeline\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.combine import SMOTETomek\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow_addons import losses\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv(\"transformed_df.csv\")\n",
    "df.rename(columns = {'y':'target'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep = df.drop(['target'], axis=1).columns\n",
    "\n",
    "indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating over & undersampling\n",
    "    \n",
    "oversampler = SMOTE(sampling_strategy=0.5)\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.8)\n",
    "\n",
    "X = df[indep]\n",
    "y = df.target\n",
    "\n",
    "print(\"------------------ Original dataset -----------------\")\n",
    "\n",
    "counter = Counter(y)\n",
    "for k,v, in counter.items():\n",
    "    dist = v / len(y) * 100\n",
    "    print(f\"Class {k} has {v} samples with {dist:.2f}%\")\n",
    "\n",
    "print(\"---------------- With Oversampling --------\")\n",
    "\n",
    "\n",
    "X_ovs, y_ovs = oversampler.fit_resample(X,y)\n",
    "\n",
    "counter1 = Counter(y_ovs)\n",
    "for k,v, in counter1.items():\n",
    "    dist = v / len(y_ovs) * 100\n",
    "    print(f\"Class {k} has {v} samples with {dist:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"---------------- With Undersampling --------\")\n",
    "\n",
    "\n",
    "X_uns, y_uns = undersampler.fit_resample(X,y)\n",
    "\n",
    "counter1 = Counter(y_uns)\n",
    "for k,v, in counter1.items():\n",
    "    dist = v / len(y_uns) * 100\n",
    "    print(f\"Class {k} has {v} samples with {dist:.2f}%\")\n",
    "\n",
    "print(\"--------- Combining Oversampling with Undersampling --------\")\n",
    "\n",
    "\n",
    "steps = [('o', oversampler), ('u', undersampler)]\n",
    "pipeline = Sampling_Pipeline(steps=steps)\n",
    "X_ovun, y_ovun = pipeline.fit_resample(X, y)\n",
    "counter3 = Counter(y_ovun)\n",
    "\n",
    "for k,v, in counter3.items():\n",
    "    dist = v / len(y_ovun) * 100\n",
    "    print(f\"Class {k} has {v} samples with {dist:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegOptimizer(X, y, standardize=False, standardize_params=None):\n",
    "    print('**We will optimize the hyper-parameters of a Logistic Regression model using Randomized Search**\\n')\n",
    "\n",
    "    #function to help us display metrics in a percentage format\n",
    "    def percentage(x):  \n",
    "        x = round(x*100,2)\n",
    "        return (str(x) + \"%\")\n",
    "\n",
    "    if standardize:\n",
    "        print(\"**Standardizing the data**\\n\")\n",
    "        for var in standardize_params:\n",
    "            X[var] = (X[var] - X[var].mean()) / X[var].std()\n",
    "        \n",
    "        print(\"**Data has been standardized**\\n\")\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state=1)\n",
    "\n",
    "    over = SMOTE()\n",
    "    X_train, y_train = over.fit_resample(X_train,y_train)\n",
    "\n",
    "    grid_params = {'C' : [0.001, 0.01, 1, 5, 10, 25, 50, 100], \n",
    "                    'penalty' : [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "                    'solver': [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "    }\n",
    "\n",
    "    logreg=LogisticRegression()\n",
    "    logreg_cv=RandomizedSearchCV(logreg, grid_params, cv = 10 , verbose = True, n_jobs= -1, scoring = \"roc_auc\")  #randomized search as opposed to gridsearch, to improve run time\n",
    "    logreg_cv.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = logreg_cv.predict(X_test)\n",
    "\n",
    "    print(\"----------------------------------- Confusion Matrix-----------------------------------\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"--------------------------------- Classification Report---------------------------------\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "    print(\"-----------------------------------------Metrics----------------------------------------\\n\")\n",
    "    print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "    print(\"ROC AUC SCORE:\" + str(roc_auc_score(y_test, y_pred)))\n",
    "    print(\"Gini (Somer's D) coefficient:\" + str((roc_auc_score(y_test, y_pred)*2-1)))\n",
    "    print('Accuracy Score : ' + percentage(accuracy_score(y_test,y_pred)))\n",
    "    print('Precision Score : ' + percentage(precision_score(y_test,y_pred)))\n",
    "    print('Recall Score : ' + percentage(recall_score(y_test,y_pred)))\n",
    "    print('F1 Score : ' + percentage(f1_score(y_test,y_pred)))\n",
    "\n",
    "    # get the values required to plot a ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    # plot the ROC curve\n",
    "    plt.plot(fpr, tpr)\n",
    "    # plot a secondary diagonal line, to plot randomness of model\n",
    "    plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "\n",
    "LogRegOptimizer(X = df[indep], y = df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also try a model where we standardize the numerical variables (not the discrete ones)\n",
    "\n",
    "standardize_params = ['age', 'balance','duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "LogRegOptimizer(X = df[indep], y = df.target, standardize = True, standardize_params = standardize_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RandomForestOptimizer(X, y):\n",
    "    print('**We will optimize the hyper-parameters of a Random Forest model using Grid Search in Python**\\n')\n",
    "\n",
    "    #function to help us display metrics in a percentage format\n",
    "    def percentage(x):  \n",
    "        x = round(x*100,2)\n",
    "        return (str(x) + \"%\")\n",
    "\n",
    "\n",
    "    #test train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify = y)\n",
    "\n",
    "    #class target frequencies after split\n",
    "    (unique, counts) = np.unique(y_train, return_counts=True)\n",
    "    frequencies = np.asarray((unique, counts)).T\n",
    "    print(\"Class target frequencies\\n\" + str(frequencies))\n",
    "\n",
    "    #combining oversampling and undersampling in a pipeline\n",
    "\n",
    "    over = SMOTE(sampling_strategy = 0.5)\n",
    "    under = RandomUnderSampler(sampling_strategy = 0.8)\n",
    "    \n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Sampling_Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    # smt = SMOTETomek(random_state=42, n_jobs = -1)\n",
    "    # X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "    # std_slc = StandardScaler()\n",
    "    rand_for = RandomForestClassifier()\n",
    "    pipe = Pipeline(steps=[#('std_slc', std_slc),\n",
    "                           ('rand_for', rand_for)])\n",
    "\n",
    "    # Creating Parameter Space\n",
    "    n_estimators = [100] # not a good hyperparameter to tune -> https://stats.stackexchange.com/questions/348245/do-we-have-to-tune-the-number-of-trees-in-a-random-forest/348246#348246\n",
    "    max_depth = [5, 8, 15, 25]\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 5] \n",
    "    criterion = ['gini', 'entropy']\n",
    "    parameters = dict(rand_for__n_estimators = n_estimators,\n",
    "                      rand_for__max_depth = max_depth,  \n",
    "                      rand_for__min_samples_split = min_samples_split, \n",
    "                      rand_for__min_samples_leaf = min_samples_leaf,\n",
    "                      rand_for__criterion = criterion)\n",
    "\n",
    "    # Creating a grid search object\n",
    "    randF_GS = RandomizedSearchCV(pipe, parameters, n_jobs=-1, cv=5, verbose = 1, scoring = \"roc_auc\")\n",
    "\n",
    "    # Fitting the grid search\n",
    "    randF_GS = randF_GS.fit(X_train, y_train)\n",
    "\n",
    "    #Prediction and scores\n",
    "    y_pred = randF_GS.predict(X_test)\n",
    "\n",
    "    #Best parameters\n",
    "    print(\"Best parameters: \" + str(randF_GS.best_params_))\n",
    "\n",
    "    #Outputs\n",
    "\n",
    "    print(\"-------- Confusion Matrix------\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"-------- Classification Report------\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"--------------- Metrics ---------------\")\n",
    "    print(\"ROC AUC SCORE:\" + str(round(roc_auc_score(y_test, y_pred))),3)\n",
    "    print(\"Gini (Somer's D) coefficient:\" + str((round(roc_auc_score(y_test, y_pred)*2-1))),3)\n",
    "    print('Accuracy Score : ' + percentage(accuracy_score(y_test,y_pred)))\n",
    "    print('Precision Score : ' + percentage(precision_score(y_test,y_pred)))\n",
    "    print('Recall Score : ' + percentage(recall_score(y_test,y_pred)))\n",
    "    print('F1 Score : ' + percentage(f1_score(y_test,y_pred)))\n",
    "\n",
    "    #Feature importances\n",
    "    importances = list(randF_GS.best_estimator_._final_estimator.feature_importances_)\n",
    "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X, importances)]  # List of tuples with variable and importance\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True) # Sort the feature importances by most important first\n",
    "    print(\"------------Variable Importances ---------\")\n",
    "    [print(\"Variable: {:20} Importance: {}\".format(*pair)) for pair in feature_importances] # Print out the feature and importances \n",
    "\n",
    "    # get the values required to plot a ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    # plot the ROC curve\n",
    "    plt.plot(fpr, tpr)\n",
    "    # plot a secondary diagonal line, to plot randomness of model\n",
    "    plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    \n",
    "RandomForestOptimizer(X = df[indep], y = df.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1840/1840 [==============================] - 3s 1ms/step - loss: 0.6508 - auc: 0.8018\n",
      "Epoch 2/5\n",
      "1840/1840 [==============================] - 3s 2ms/step - loss: 0.4495 - auc: 0.8673\n",
      "Epoch 3/5\n",
      "1840/1840 [==============================] - 3s 1ms/step - loss: 0.4173 - auc: 0.8853\n",
      "Epoch 4/5\n",
      "1840/1840 [==============================] - 3s 1ms/step - loss: 0.4012 - auc: 0.8939\n",
      "Epoch 5/5\n",
      "1840/1840 [==============================] - 3s 1ms/step - loss: 0.3925 - auc: 0.9000\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.3667 - auc: 0.8569\n",
      "[0.3667181730270386, 0.8569298982620239]\n",
      "354/354 [==============================] - 0s 991us/step\n",
      "-------- Confusion Matrix------\n",
      "[[8191 1775]\n",
      " [ 378  959]]\n",
      "-------- Classification Report------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88      9966\n",
      "           1       0.35      0.72      0.47      1337\n",
      "\n",
      "    accuracy                           0.81     11303\n",
      "   macro avg       0.65      0.77      0.68     11303\n",
      "weighted avg       0.88      0.81      0.84     11303\n",
      "\n",
      "--------------- Metrics ---------------\n",
      "ROC AUC SCORE:0.77\n",
      "Gini (Somer's D) coefficient:0.539\n",
      "Accuracy Score : 80.95%\n",
      "Precision Score : 35.08%\n",
      "Recall Score : 71.73%\n",
      "F1 Score : 47.11%\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('target', 1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "over = SMOTETomek()\n",
    "X_train, y_train = over.fit_resample(X_train,y_train)\n",
    "\n",
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(50, input_dim=X_train.shape[1], kernel_initializer='normal',activation='relu'), #input layer \n",
    "        keras.layers.Dropout(0.25),\n",
    "        keras.layers.Dense(50, kernel_initializer='normal', activation='relu'), #hidden layer\n",
    "        keras.layers.Dropout(0.25),\n",
    "        keras.layers.Dense(1, activation='sigmoid') # output layer with 1 node; sigmoid function will convert all outputs between 0 and 1\n",
    "    \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['AUC'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=5)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=5, class_weight = weights)\n",
    "    \n",
    "\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    #rounding the values since the last Dense layers turns the predicted values into probabilities, threshold\n",
    " \n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "\n",
    "    #Results\n",
    "\n",
    "    def percentage(x):  \n",
    "        x = round(x*100,2)\n",
    "        return (str(x) + \"%\")\n",
    "    \n",
    "    print(\"-------- Confusion Matrix------\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"-------- Classification Report------\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"--------------- Metrics ---------------\")\n",
    "    print(\"ROC AUC SCORE:\" + str(round(roc_auc_score(y_test, y_pred),3)))\n",
    "    print(\"Gini (Somer's D) coefficient:\" + str(round(roc_auc_score(y_test, y_pred)*2-1,3)))\n",
    "    print('Accuracy Score : ' + percentage(accuracy_score(y_test,y_pred)))\n",
    "    print('Precision Score : ' + percentage(precision_score(y_test,y_pred)))\n",
    "    print('Recall Score : ' + percentage(recall_score(y_test,y_pred)))\n",
    "    print('F1 Score : ' + percentage(f1_score(y_test,y_pred)))\n",
    "\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1747805bfdf7e5202ab7b3cd6fa8f118e6fcddb135f7d35fd21660df307704da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
